{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4856919a",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github.com/beatrizbsperes/LiDARClassification/blob/main/LiDARClassificationRoutine_colab.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db859049",
   "metadata": {},
   "source": [
    "## Install \n",
    "\n",
    "Comment out the following block if you are launching binder , those are the extra requirements needed for the google collab to run ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f72f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install numpy laspy open3d matplotlib scikit-learn scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b111c65-0bbb-4402-9c65-e5aeb42de4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import laspy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial import cKDTree\n",
    "import open3d as o3d\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b20feaa3-8487-4691-be8e-dc668a729298",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LidarProcessor:\n",
    "    UNCLASSIFIED = 0\n",
    "    GROUND = 1\n",
    "    BUILDING = 2\n",
    "    VEGETATION = 3\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the processor\"\"\"\n",
    "        self.data = None\n",
    "        self.features = None\n",
    "        self.output_widget = widgets.Output()\n",
    "    \n",
    "    def load_file(self, file_path):\n",
    "        \"\"\"Load LAS file, return points and associated data\"\"\"\n",
    "        print(f\"Loading LAS file from: {file_path}\")\n",
    "        try:\n",
    "            las = laspy.read(file_path)\n",
    "            #Extract basic point data\n",
    "            points = np.vstack((las.x, las.y, las.z)).transpose()\n",
    "            \n",
    "            #Extract additional attributes \n",
    "            intensity = getattr(las, 'intensity', np.zeros(len(points)))\n",
    "            return_number = getattr(las, 'return_number', np.ones(len(points)))\n",
    "            number_of_returns = getattr(las, 'number_of_returns', np.ones(len(points)))\n",
    "            \n",
    "            #Storing everything \n",
    "            self.data = {\n",
    "                'points': points,\n",
    "                'intensity': intensity,\n",
    "                'return_number': return_number,\n",
    "                'number_of_returns': number_of_returns,\n",
    "                'las_header': las.header,\n",
    "                'classification': np.zeros(len(points), dtype=np.uint8)  #Initialize as unclassified\n",
    "            }\n",
    "            \n",
    "            print(f\"Successfully loaded {len(points)} points\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading LAS file: {e}\")\n",
    "            return False\n",
    "\n",
    "    def downsample(self, voxel_size=0.2):\n",
    "        \"\"\"Downsample the point cloud for easier computation\"\"\"\n",
    "        if self.data is None:\n",
    "            print(\"No data loaded\")\n",
    "            return False\n",
    "            \n",
    "        print(f\"Downsampling point cloud with voxel size: {voxel_size}...\")\n",
    "        \n",
    "        #Create open3d point cloud and downsample\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(self.data['points'])\n",
    "        downsampled_pcd = pcd.voxel_down_sample(voxel_size=voxel_size)\n",
    "        downsampled_points = np.asarray(downsampled_pcd.points)\n",
    "        \n",
    "        #Create KD-tree to find corresponding original points\n",
    "        kdtree = cKDTree(self.data['points'])\n",
    "        _, indices = kdtree.query(downsampled_points)\n",
    "        \n",
    "        #Create downsampled data dictionary\n",
    "        original_data = self.data\n",
    "        self.data = {\n",
    "            'points': downsampled_points,\n",
    "            'intensity': original_data['intensity'][indices],\n",
    "            'return_number': original_data['return_number'][indices],\n",
    "            'number_of_returns': original_data['number_of_returns'][indices],\n",
    "            'las_header': original_data['las_header'],\n",
    "            'classification': np.zeros(len(downsampled_points), dtype=np.uint8),\n",
    "            'original_indices': indices  #Store indices of original points\n",
    "        }\n",
    "        \n",
    "        print(f\"Downsampled from {len(original_data['points'])} to {len(downsampled_points)} points\")\n",
    "        return True\n",
    "\n",
    "    def extract_ground(self, grid_size=1.0, height_threshold=0.2, slope_threshold=20.0):\n",
    "        \"\"\"Extract ground points using a grid based thingy\"\"\"\n",
    "        if self.data is None:\n",
    "            print(\"No data loaded\")\n",
    "            return False\n",
    "            \n",
    "        print(\"Extracting ground points...\")\n",
    "        points = self.data['points']\n",
    "        \n",
    "        #Create a 2D grid\n",
    "        x_min, y_min = np.min(points[:, 0]), np.min(points[:, 1])\n",
    "        x_max, y_max = np.max(points[:, 0]), np.max(points[:, 1])\n",
    "        \n",
    "        #Calculate grid dimensions\n",
    "        grid_x = int((x_max - x_min) / grid_size) + 1\n",
    "        grid_y = int((y_max - y_min) / grid_size) + 1\n",
    "        \n",
    "        #Initialize grid with high values\n",
    "        grid = np.ones((grid_x, grid_y)) * float('inf')\n",
    "        grid_points = {}\n",
    "        \n",
    "        #Find lowest point in each grid cell \n",
    "        for i, (x, y, z) in enumerate(points):\n",
    "            gx = min(grid_x - 1, int((x - x_min) / grid_size))\n",
    "            gy = min(grid_y - 1, int((y - y_min) / grid_size))\n",
    "            \n",
    "            if z < grid[gx, gy]:\n",
    "                grid[gx, gy] = z\n",
    "                grid_points[(gx, gy)] = i\n",
    "        \n",
    "        #Identify ground cells based on slope\n",
    "        ground_indices = []\n",
    "        for (gx, gy), idx in grid_points.items():\n",
    "            is_ground = True\n",
    "            \n",
    "            #Check neighboring cells\n",
    "            for dx in [-1, 0, 1]:\n",
    "                for dy in [-1, 0, 1]:\n",
    "                    nx, ny = gx + dx, gy + dy\n",
    "                    if (nx >= 0 and nx < grid_x and ny >= 0 and ny < grid_y and \n",
    "                        grid[nx, ny] != float('inf')):\n",
    "                        #Calculate slope between cells\n",
    "                        distance = np.sqrt(dx**2 + dy**2) * grid_size\n",
    "                        if distance > 0:  #Avoid checking the cell itself\n",
    "                            height_diff = abs(grid[gx, gy] - grid[nx, ny])\n",
    "                            slope = np.degrees(np.arctan(height_diff / distance))\n",
    "                            if slope > slope_threshold:\n",
    "                                is_ground = False\n",
    "                                break\n",
    "                if not is_ground:\n",
    "                    break\n",
    "                    \n",
    "            if is_ground:\n",
    "                ground_indices.append(idx)\n",
    "        \n",
    "        #Mark initial ground points\n",
    "        classifications = self.data['classification']\n",
    "        for idx in ground_indices:\n",
    "            classifications[idx] = self.GROUND\n",
    "        \n",
    "        #Refine ground classification using height threshold\n",
    "        if ground_indices:\n",
    "            kdtree = cKDTree(points[ground_indices][:, 0:2])  #2D KD-tree of ground points\n",
    "            \n",
    "            for i, (x, y, z) in enumerate(points):\n",
    "                if classifications[i] != self.GROUND:  #f not already classified as ground\n",
    "                    #Find closest ground point\n",
    "                    distance, idx = kdtree.query([x, y])\n",
    "                    if distance < grid_size * 2:  #Only compare with nearby ground points\n",
    "                        ground_z = points[ground_indices[idx]][2]\n",
    "                        if z - ground_z < height_threshold:\n",
    "                            classifications[i] = self.GROUND  #Classify as ground\n",
    "        \n",
    "        print(f\"Ground extraction complete. {np.sum(classifications == self.GROUND)} points classified as ground.\")\n",
    "        return True\n",
    "\n",
    "    def segmentation(self):\n",
    "        \"\"\"Compute features for classification\"\"\"\n",
    "        if self.data is None:\n",
    "            print(\"No data loaded\")\n",
    "            return False\n",
    "            \n",
    "        print(\"Computing features for classification...\")\n",
    "        \n",
    "        points = self.data['points']\n",
    "        intensity = self.data['intensity']\n",
    "        return_number = self.data['return_number']\n",
    "        number_of_returns = self.data['number_of_returns']\n",
    "        classifications = self.data['classification']\n",
    "        \n",
    "        #Create KD-tree for nearest neighbor search\n",
    "        kdtree = cKDTree(points)\n",
    "\n",
    "        #Features: height, height range, density, linearity, planarity, sphericity, return number, number of returns, return ratio, intensity\n",
    "        self.features = np.zeros((len(points), 10))\n",
    "        \n",
    "        #Calculate height above ground for all points\n",
    "        ground_indices = np.where(classifications == self.GROUND)[0]\n",
    "        if len(ground_indices) > 0:\n",
    "            ground_points = points[ground_indices]\n",
    "            ground_kdtree = cKDTree(ground_points[:, 0:2])\n",
    "            \n",
    "            #For each point, find closest ground point\n",
    "            distances, indices = ground_kdtree.query(points[:, 0:2])\n",
    "            ground_z = ground_points[indices, 2]\n",
    "            \n",
    "            #Height above ground\n",
    "            self.features[:, 0] = points[:, 2] - ground_z\n",
    "        \n",
    "        #Process points in batches as in segmentation\n",
    "        batch_size = 1000\n",
    "        for start_idx in range(0, len(points), batch_size):\n",
    "            end_idx = min(start_idx + batch_size, len(points))\n",
    "            batch_points = points[start_idx:end_idx]\n",
    "            \n",
    "            #Find points within search radius\n",
    "            distances, neighbors_indices = kdtree.query(batch_points, k=30)\n",
    "            \n",
    "            for i in range(end_idx - start_idx):\n",
    "                #Get indices of neighboring points within 2m\n",
    "                valid_neighbors = neighbors_indices[i][distances[i] < 2.0]\n",
    "                \n",
    "                if len(valid_neighbors) < 3:\n",
    "                    continue\n",
    "                    \n",
    "                #Extract neighborhood points\n",
    "                neighbors = points[valid_neighbors]\n",
    "                \n",
    "                #Local height range\n",
    "                self.features[start_idx + i, 1] = np.max(neighbors[:, 2]) - np.min(neighbors[:, 2])\n",
    "                \n",
    "                #Local point density\n",
    "                self.features[start_idx + i, 2] = len(valid_neighbors) / 33.5  #Approx volume of 2m radius sphere\n",
    "                \n",
    "                #Eigenvalue-based features\n",
    "                if len(valid_neighbors) >= 3:\n",
    "                    #Compute covariance matrix and eigenvalues\n",
    "                    centered_points = neighbors - np.mean(neighbors, axis=0)\n",
    "                    cov = np.cov(centered_points.T)\n",
    "                    eigenvalues = np.sort(np.linalg.eigvals(cov))[::-1]  #Sort in descending order\n",
    "                    \n",
    "                    if np.sum(eigenvalues) > 0:\n",
    "                        #Normalize eigenvalues\n",
    "                        eigenvalues = eigenvalues / np.sum(eigenvalues)\n",
    "                        \n",
    "                        #Geometry features\n",
    "                        self.features[start_idx + i, 3] = (eigenvalues[0] - eigenvalues[1]) / eigenvalues[0]  #Linearity\n",
    "                        self.features[start_idx + i, 4] = (eigenvalues[1] - eigenvalues[2]) / eigenvalues[0]  #Planarity\n",
    "                        self.features[start_idx + i, 5] = eigenvalues[2] / eigenvalues[0]  #Sphericity\n",
    "        \n",
    "        #Return information and intensity (already available per point)\n",
    "        self.features[:, 6] = return_number\n",
    "        self.features[:, 7] = number_of_returns\n",
    "        self.features[:, 8] = return_number / np.maximum(number_of_returns, 1)  #Avoid division by zero\n",
    "        self.features[:, 9] = intensity\n",
    "\n",
    "        print(\"\\n\")\n",
    "        print(\"For point number 1: \\n Height abouve ground:\", self.features[1, 0], \"\\n Local height range:\", self.features[1, 1], \"\\n Local point density:\", self.features[1, 2],\n",
    "             \"\\n Liniarity:\", self.features[1, 3], \"\\n Planarity:\", self.features[1, 4], \"\\n Sphericity:\", self.features[1, 5],\n",
    "             \"\\n Return number:\", self.features[1, 6], \"\\n Number of returns:\", self.features[1, 7], \"\\n Return ratio:\", self.features[1, 8],\n",
    "             \"\\n Intensity:\", self.features[1, 9])\n",
    "        print(\"\\n\")\n",
    "        print(\"For point number 101: \\n Height abouve ground:\", self.features[100, 0], \"\\n Local height range:\", self.features[100, 1], \"\\n Local point density:\", self.features[100, 2],\n",
    "             \"\\n Liniarity:\", self.features[100, 3], \"\\n Planarity:\", self.features[100, 4], \"\\n Sphericity:\", self.features[100, 5],\n",
    "             \"\\n Return number:\", self.features[100, 6], \"\\n Number of returns:\", self.features[100, 7], \"\\n Return ratio:\", self.features[100, 8],\n",
    "             \"\\n Intensity:\", self.features[100, 9])\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        print(\"Segmentation complete.\")\n",
    "        return True\n",
    "\n",
    "    def classify_points(self):\n",
    "        \"\"\"Classify points based on computed segmentation\"\"\"\n",
    "        if self.data is None or self.features is None:\n",
    "            print(\"Data or features missing\")\n",
    "            return False\n",
    "            \n",
    "        print(\"Classifying points...\")\n",
    "        \n",
    "        classifications = self.data['classification']\n",
    "        \n",
    "        #Define thresholds\n",
    "        height_threshold_building = 1.0  #Minimum height for buildings\n",
    "        height_threshold_vegetation = 1.0  #Minimum height for vegetation\n",
    "        planarity_threshold = 0.6  #Higher values indicate planar structures (buildings)\n",
    "        sphericity_threshold = 0.2  #Higher values indicate more spherical structures (vegetation)\n",
    "        \n",
    "        #Get non-ground points\n",
    "        non_ground_indices = np.where(classifications != self.GROUND)[0]\n",
    "        \n",
    "        #Classify non-ground points based on features\n",
    "        for i in non_ground_indices:\n",
    "            height = self.features[i, 0]  #Height above ground\n",
    "            planarity = self.features[i, 4]  #Planarity\n",
    "            sphericity = self.features[i, 5]  #Sphericity\n",
    "            \n",
    "            #Classification rules\n",
    "            if height < height_threshold_vegetation:\n",
    "                continue  \n",
    "            \n",
    "            if planarity > planarity_threshold and sphericity < sphericity_threshold and height > height_threshold_building:\n",
    "                classifications[i] = self.BUILDING  #Building\n",
    "            elif sphericity > sphericity_threshold or (height > height_threshold_vegetation and planarity < 0.4):\n",
    "                classifications[i] = self.VEGETATION  #Vegetation and trees\n",
    "        \n",
    "        #Count classified points\n",
    "        class_counts = {\n",
    "            \"Ground\": np.sum(classifications == self.GROUND),\n",
    "            \"Building\": np.sum(classifications == self.BUILDING),\n",
    "            \"Vegetation\": np.sum(classifications == self.VEGETATION),\n",
    "            \"Unclassified\": np.sum(classifications == self.UNCLASSIFIED)\n",
    "        }\n",
    "        \n",
    "        print(f\"Classification complete:\")\n",
    "        for cls, count in class_counts.items():\n",
    "            print(f\"  {cls} points: {count}\")\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def refine_with_ml(self, train_percentage=0.3):\n",
    "        \"\"\"Refine classification using Random Forest\"\"\"\n",
    "        if self.data is None or self.features is None:\n",
    "            print(\"Data or features missing\")\n",
    "            return False\n",
    "            \n",
    "        print(\"Refining classification with Random Forest...\")\n",
    "        \n",
    "        classifications = self.data['classification']\n",
    "        \n",
    "        #Get indices of classified points for training\n",
    "        ground_indices = np.where(classifications == self.GROUND)[0]\n",
    "        building_indices = np.where(classifications == self.BUILDING)[0]\n",
    "        tree_indices = np.where(classifications == self.VEGETATION)[0]\n",
    "        \n",
    "        #Sample points for training\n",
    "        def sample(indices, percentage=train_percentage):\n",
    "            if len(indices) == 0:\n",
    "                return np.array([])\n",
    "            sample_size = max(int(len(indices) * percentage), 1)\n",
    "            return np.random.choice(indices, sample_size, replace=False)\n",
    "        \n",
    "        #Create training dataset\n",
    "        train_indices = np.concatenate([\n",
    "            sample(ground_indices),\n",
    "            sample(building_indices), \n",
    "            sample(tree_indices)\n",
    "        ])\n",
    "        \n",
    "        if len(train_indices) < 10:\n",
    "            print(\"Not enough classified points for ML training. Skipping refinement.\")\n",
    "            return False\n",
    "        \n",
    "        #Train Random Forest classifier\n",
    "        X_train = self.features[train_indices]\n",
    "        y_train = classifications[train_indices]\n",
    "        \n",
    "        clf = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42, n_jobs=-1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        #Only predict for unclassified points\n",
    "        unclassified_indices = np.where(classifications == self.UNCLASSIFIED)[0]\n",
    "        \n",
    "        if len(unclassified_indices) > 0:\n",
    "            X_unclassified = self.features[unclassified_indices]\n",
    "            y_pred = clf.predict(X_unclassified)\n",
    "            classifications[unclassified_indices] = y_pred\n",
    "        \n",
    "        #Update counts\n",
    "        class_counts = {\n",
    "            \"Ground\": np.sum(classifications == self.GROUND),\n",
    "            \"Building\": np.sum(classifications == self.BUILDING),\n",
    "            \"Vegetation\": np.sum(classifications == self.VEGETATION),\n",
    "            \"Unclassified\": np.sum(classifications == self.UNCLASSIFIED)\n",
    "        }\n",
    "        \n",
    "        print(f\"Classification refinement complete:\")\n",
    "        for cls, count in class_counts.items():\n",
    "            print(f\"  {cls} points: {count}\")\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def visualize(self, max_points=50000):\n",
    "        \"\"\"Visualize the classified point cloud using matplotlib\"\"\"\n",
    "        if self.data is None:\n",
    "            print(\"No data loaded\")\n",
    "            return None\n",
    "            \n",
    "        print(\"Visualizing classified point cloud...\")\n",
    "        \n",
    "        points = self.data['points']\n",
    "        classifications = self.data['classification']\n",
    "        \n",
    "        #Define colors for different classes\n",
    "        colors = np.zeros((len(points), 3))\n",
    "        colors[classifications == self.UNCLASSIFIED] = [0.7, 0.7, 0.7]  #Unclassified - gray\n",
    "        colors[classifications == self.GROUND] = [0.8, 0.5, 0.2]  #Ground - brown\n",
    "        colors[classifications == self.BUILDING] = [1.0, 0.0, 0.0]  #Buildings - red\n",
    "        colors[classifications == self.VEGETATION] = [0.0, 0.8, 0.0]  #Trees and vegetation - green\n",
    "        \n",
    "        #Downsample points for visualization\n",
    "        if len(points) > max_points:\n",
    "            indices = np.random.choice(len(points), max_points, replace=False)\n",
    "            points_to_plot = points[indices]\n",
    "            colors_to_plot = colors[indices]\n",
    "        else:\n",
    "            points_to_plot = points\n",
    "            colors_to_plot = colors\n",
    "        \n",
    "        #Create 3d figure\n",
    "        fig = plt.figure(figsize=(10, 8))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        \n",
    "        #Plot points\n",
    "        ax.scatter(\n",
    "            points_to_plot[:, 0], \n",
    "            points_to_plot[:, 1], \n",
    "            points_to_plot[:, 2],\n",
    "            c=colors_to_plot, \n",
    "            s=1,\n",
    "            marker='.'\n",
    "        )\n",
    "        \n",
    "        #Set labels and title\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "        ax.set_title('Classified Point Cloud')\n",
    "        \n",
    "        #Add legend\n",
    "        legend_elements = [\n",
    "            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=[0.7, 0.7, 0.7], markersize=10, label='Unclassified'),\n",
    "            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=[0.8, 0.5, 0.2], markersize=10, label='Ground'),\n",
    "            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=[1.0, 0.0, 0.0], markersize=10, label='Buildings'),\n",
    "            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=[0.0, 0.8, 0.0], markersize=10, label='Trees/Vegetation')\n",
    "        ]\n",
    "        ax.legend(handles=legend_elements, loc='upper right')\n",
    "        \n",
    "        #Set equal aspect ratio\n",
    "        max_range = np.array([\n",
    "            points_to_plot[:, 0].max() - points_to_plot[:, 0].min(),\n",
    "            points_to_plot[:, 1].max() - points_to_plot[:, 1].min(),\n",
    "            points_to_plot[:, 2].max() - points_to_plot[:, 2].min()\n",
    "        ]).max() / 2.0\n",
    "        \n",
    "        mid_x = (points_to_plot[:, 0].max() + points_to_plot[:, 0].min()) * 0.5\n",
    "        mid_y = (points_to_plot[:, 1].max() + points_to_plot[:, 1].min()) * 0.5\n",
    "        mid_z = (points_to_plot[:, 2].max() + points_to_plot[:, 2].min()) * 0.5\n",
    "        \n",
    "        ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "        ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "        ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return fig\n",
    "\n",
    "    def visualize_with_open3d(self, point_size=1.0, max_points=500000):\n",
    "        \"\"\"Visualize the classified point cloud using Open3D\"\"\"\n",
    "        if self.data is None:\n",
    "            print(\"No data loaded\")\n",
    "            return False\n",
    "            \n",
    "        print(\"Creating Open3D visualization...\")\n",
    "        \n",
    "        points = self.data['points']\n",
    "        classifications = self.data['classification']\n",
    "        \n",
    "        #Downsample for better performance if needed\n",
    "        if len(points) > max_points:\n",
    "            print(f\"Point cloud is large ({len(points)} points). Downsampling for visualization...\")\n",
    "            indices = np.random.choice(len(points), max_points, replace=False)\n",
    "            vis_points = points[indices]\n",
    "            vis_classifications = classifications[indices]\n",
    "        else:\n",
    "            vis_points = points\n",
    "            vis_classifications = classifications\n",
    "        \n",
    "        #Create Open3D point cloud\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(vis_points)\n",
    "        \n",
    "        #Define colors for different classes\n",
    "        colors = np.zeros((len(vis_points), 3))\n",
    "        colors[vis_classifications == self.UNCLASSIFIED] = [0.7, 0.7, 0.7]  #Unclassified - gray\n",
    "        colors[vis_classifications == self.GROUND] = [0.8, 0.5, 0.2]  #Ground - brown\n",
    "        colors[vis_classifications == self.BUILDING] = [1.0, 0.0, 0.0]  #Buildings - red\n",
    "        colors[vis_classifications == self.VEGETATION] = [0.0, 0.8, 0.0]  #Trees/Vegetation - green\n",
    "        \n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        \n",
    "        #Initialize visualizer\n",
    "        vis = o3d.visualization.Visualizer()\n",
    "        vis.create_window(window_name=\"Classified Point Cloud\", width=1024, height=768)\n",
    "        vis.add_geometry(pcd)\n",
    "        \n",
    "        #Set rendering options\n",
    "        opt = vis.get_render_option()\n",
    "        opt.background_color = np.array([0.1, 0.1, 0.1])\n",
    "        opt.point_size = point_size\n",
    "        \n",
    "        #Start visualization\n",
    "        print(\"Open3D visualization ready. Close the window to continue.\")\n",
    "        vis.run()\n",
    "        vis.destroy_window()\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def export_result(self, output_path):\n",
    "        \"\"\"Export the classified point cloud as LAS file\"\"\"\n",
    "        if self.data is None:\n",
    "            print(\"No data loaded\")\n",
    "            return False\n",
    "            \n",
    "        print(f\"Exporting classified point cloud to: {output_path}\")\n",
    "        \n",
    "        try:\n",
    "            #Create new LAS file with the same header as input\n",
    "            header = self.data['las_header']\n",
    "            new_las = laspy.create(point_format=header.point_format, file_version=header.version)\n",
    "            \n",
    "            #Copy header info\n",
    "            new_las.header.offsets = header.offsets\n",
    "            new_las.header.scales = header.scales\n",
    "            \n",
    "            #Set coordinates\n",
    "            points = self.data['points']\n",
    "            new_las.x = points[:, 0]\n",
    "            new_las.y = points[:, 1]\n",
    "            new_las.z = points[:, 2]\n",
    "            \n",
    "            #Set other attributes\n",
    "            new_las.intensity = self.data['intensity']\n",
    "            new_las.return_number = self.data['return_number']\n",
    "            new_las.number_of_returns = self.data['number_of_returns']\n",
    "            \n",
    "            #Set classification\n",
    "            new_las.classification = self.data['classification']\n",
    "            \n",
    "            #Write to file\n",
    "            new_las.write(output_path)\n",
    "            print(f\"Export successful: {output_path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error exporting classified point cloud: {e}\")\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26def43d",
   "metadata": {},
   "source": [
    "## Google Collab Section \n",
    "Run this if you are using google collab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc06b76c-61ff-46c2-bfdd-2e364a29f199",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m output\n\u001b[0;32m      2\u001b[0m output\u001b[38;5;241m.\u001b[39menable_custom_widget_manager()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mipywidgets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwidgets\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def run_lidar_processor_colab():\n",
    "    processor = LidarProcessor()\n",
    "    \n",
    "    file_upload = widgets.FileUpload(\n",
    "        accept='.las',\n",
    "        multiple=False,\n",
    "        description='Upload LAS File'\n",
    "    )\n",
    "    \n",
    "    voxel_size_input = widgets.FloatSlider(\n",
    "        value=0.2, min=0.05, max=1.0, step=0.05,\n",
    "        description='Voxel Size',\n",
    "        continuous_update=False,\n",
    "        tooltip='Higher = more downsample, faster but less accurate'\n",
    "    )\n",
    "    \n",
    "    max_points_input = widgets.IntSlider(\n",
    "        value=50000, min=10000, max=500000, step=10000,\n",
    "        description='Viz Points',\n",
    "        continuous_update=False,\n",
    "        tooltip='Max points for visualization'\n",
    "    )\n",
    "    \n",
    "    submit_button = widgets.Button(\n",
    "        description='Process Point Cloud',\n",
    "        button_style='info'\n",
    "    )\n",
    "    \n",
    "    output_area = widgets.Output()\n",
    "    processor.output_widget = output_area\n",
    "    \n",
    "    ui = widgets.VBox([\n",
    "        file_upload,\n",
    "        widgets.HBox([voxel_size_input, max_points_input]),\n",
    "        submit_button,\n",
    "        output_area\n",
    "    ])\n",
    "    display(ui)\n",
    "    \n",
    "    def process_file(_):\n",
    "        with output_area:\n",
    "            output_area.clear_output()\n",
    "            \n",
    "            if not file_upload.value:\n",
    "                print(\"Please upload a .las file first.\")\n",
    "                return\n",
    "            uploaded_file = file_upload.value[0]\n",
    "            name = uploaded_file['name']\n",
    "            fileinfo = uploaded_file\n",
    "            with open(name, 'wb') as f:\n",
    "                f.write(fileinfo['content'])\n",
    "            file_path = name\n",
    "            \n",
    "            print(f\"Processing: {file_path}\")\n",
    "            progress = widgets.IntProgress(min=0, max=9, description='Step:')\n",
    "            display(progress)\n",
    "            \n",
    "            if not processor.load_file(file_path):\n",
    "                print(\"✖️ Failed to load. Check your file and try again.\")\n",
    "                return\n",
    "            progress.value += 1\n",
    "            \n",
    "            processor.downsample(voxel_size=voxel_size_input.value)\n",
    "            progress.value += 1\n",
    "            \n",
    "            processor.visualize(max_points=max_points_input.value)\n",
    "            progress.value += 1\n",
    "            \n",
    "            processor.extract_ground()\n",
    "            progress.value += 1\n",
    "            \n",
    "            processor.visualize(max_points=max_points_input.value)\n",
    "            progress.value += 1\n",
    "            \n",
    "            processor.segmentation()\n",
    "            progress.value += 1\n",
    "            \n",
    "            processor.classify_points()\n",
    "            progress.value += 1\n",
    "            \n",
    "            processor.visualize(max_points=max_points_input.value)\n",
    "            progress.value += 1\n",
    "            \n",
    "            processor.refine_with_ml()\n",
    "            progress.value += 1\n",
    "            \n",
    "            processor.visualize(max_points=max_points_input.value)\n",
    "            \n",
    "            add_additional_options(processor, file_path, max_points_input, output_area)\n",
    "    \n",
    "    def add_additional_options(proc, file_path, max_points_widget, out_area):\n",
    "        open3d_btn = widgets.Button(description='3D View', button_style='success')\n",
    "        point_size = widgets.FloatSlider(\n",
    "            value=1.0, min=0.5, max=5.0, step=0.5,\n",
    "            description='Point Size'\n",
    "        )\n",
    "        export_path = widgets.Text(\n",
    "            value=file_path.replace('.las','_classified.las'),\n",
    "            description='Save As',\n",
    "            layout=widgets.Layout(width='70%')\n",
    "        )\n",
    "        export_btn = widgets.Button(description='Export', button_style='warning')\n",
    "        \n",
    "        display(widgets.VBox([\n",
    "            widgets.Label(\"Additional Options:\"),\n",
    "            widgets.HBox([open3d_btn, point_size]),\n",
    "            widgets.HBox([export_path, export_btn])\n",
    "        ]))\n",
    "        \n",
    "        def on_viz(_):\n",
    "            with out_area:\n",
    "                proc.visualize_with_open3d(\n",
    "                    point_size=point_size.value,\n",
    "                    max_points=max_points_widget.value\n",
    "                )\n",
    "        def on_export(_):\n",
    "            with out_area:\n",
    "                out_file = export_path.value.strip()\n",
    "                if out_file:\n",
    "                    proc.export_result(out_file)\n",
    "                    print(f\"Exported to {out_file}\")\n",
    "                else:\n",
    "                    print(\"Please specify a valid export path.\")\n",
    "        \n",
    "        open3d_btn.on_click(on_viz)\n",
    "        export_btn.on_click(on_export)\n",
    "    \n",
    "    submit_button.on_click(process_file)\n",
    "\n",
    "run_lidar_processor_colab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0fe21f",
   "metadata": {},
   "source": [
    "## Download Sample Data \n",
    "\n",
    "This is where you can find the sample data to download : \n",
    "https://github.com/beatrizbsperes/LiDARClassification/tree/main/data\n",
    "\n",
    "Sample 1 : https://github.com/beatrizbsperes/LiDARClassification/raw/refs/heads/main/data/test_area_1.las "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LiDAR)",
   "language": "python",
   "name": "lidarclassification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
